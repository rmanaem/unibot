COMP 474/6741 Intelligent Systems (Winter 2022) Worksheet #5: Recommender Systems Task 1. Let’s take some movies that have been #tagged (or categorized) as follows: Action Comedy Sci-Fi Horror Drama Romance length Movie 1 4 8 6 3 0 0 Movie 2 0 5 0 8 5 0 Movie 3 1 4 0 3 0 10 −−−−→ So, each movie becomes a 6-dimensional vector of tags t , e.g., Movie = (cid:104)4, 8, 6, 3, 0, 0(cid:105). Compute the length i 1 (cid:112) of each movie vector, which is deﬁned as ||m(cid:126) || = t2 + . . . + t2 (rounded to two signiﬁcant digits). 1 n Task 2. Now you can normalize the vectors, by dividing the raw count of each tag t by the length ti : i ||m(cid:126) || Action Comedy Sci-Fi Horror Drama Romance Movie 1 Movie 2 Movie 3 Use 4 signiﬁcant digits for this table (protip: the length of each movie vector must now be 1). Task 3. We can now compute how similar the movies are, by computing their cosine similarity. Since the (cid:80) vectors are normalized, this is simply their dot product: sim(m(cid:126) , (cid:126)n) = cos(m(cid:126) , (cid:126)n) = m(cid:126) · (cid:126)n = m · n : i i i Movie 1 Movie 2 Movie 3 Movie 1 1 Movie 2 1 Movie 3 1 This is the information we need for an item-to-item recommendation engine: Now we can answer the question, which movie is interesting to (buy, watch) for a customer who (bought, watched) Movie 1? Task 4. Now we want to personalize the recommendations. We collected the following proﬁles about the movies watched (bought) by our users in the past: Action Comedy Sci-Fi Horror Drama Romance length Jane 1 2 1 1 1 0 Joe 0 1 0 1 0 1 Compute the length of each user vector and normalize it like before: Action Comedy Sci-Fi Horror Drama Romance Jane Joe Task 5. Now we can answer the question which movie a user is interested in. Compute the cosine similarities between the user vectors and the movie vectors: Movie 1 Movie 2 Movie 3 Jane Joe BreakPage COMP 474/6741 Worksheet: Recommender Systems Winter 2022 Task 6. Consider the results from three diﬀerent recommender systems below: Here, X1–X5 are the items (movies, photos, songs, . . . ) that the systems should have recommended as relevant for a speciﬁc user. The remaining 495 instances are not relevant for the user. A checkmark indicates that a system recommended this item to the user (the ﬁrst Target column is the ground truth): Evaluate the performance of the three systems using the measures Precision and Recall : Precision Recall #correct system recommendations precision = system 1 #all system recommendations system 2 #correct system recommendations recall = system 3 #all correct recommendations k Task 7. Now we’re looking at ranked results. Based on the output below, compute precision@k = 1 · (cid:80) rel(c) k c=1 for the three recommender systems (for k = 1, 2, 3): rel(k) precision@k 1 2 3 1 2 3 AP@3 system 1 1 0 0 system 2 0 1 0 system 3 0 0 1 That is, here each system got exactly one recommendation right, but in a diﬀerent position. N Task 8. Moving on to the average precision, AP @N = 1 (cid:80) precision@k ·rel(k). Compute the AP@3 and m k=1 add it to the table above. Here, assume m = 3 (i.e., there could have been 3 correct recommendations in the top-3). Note the diﬀerence in the AP@3 for the three systems! Task 9. Create a content vector for the movie description m =“A comedy with zombies.” Start by ﬁlling 1 in the tf values below. Then compute idf = log N (assume N = 10,000,000) and tf-idf = (1 + log tf )×idf. 10 df t,d Finally, compute the normalized vector (cid:126)q as before (in Tasks 1&2) from the tf-idf vector: m 1 token tf df idf tf-idf q i action 50,000 comedy 10,000 zombies 100,000 romantic 10,000 You can now use these vectors for (cosine) similarity calculations to ﬁnd recommendations as before, but this time based on the content of an item (like a movie description). BreakPage 